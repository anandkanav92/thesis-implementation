{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.100\n",
       "1      0.100\n",
       "2      0.100\n",
       "6      0.100\n",
       "7      0.100\n",
       "8      0.100\n",
       "12     0.668\n",
       "13     0.540\n",
       "15     0.418\n",
       "16     0.564\n",
       "19     0.544\n",
       "20     0.708\n",
       "22     0.742\n",
       "23     0.100\n",
       "24     0.100\n",
       "27     0.100\n",
       "29     0.100\n",
       "30     0.330\n",
       "31     0.330\n",
       "32     0.672\n",
       "33     0.100\n",
       "34     0.100\n",
       "35     0.332\n",
       "36     0.672\n",
       "37     0.292\n",
       "38     0.526\n",
       "40     0.744\n",
       "42     0.672\n",
       "43     0.702\n",
       "44     0.744\n",
       "       ...  \n",
       "366    0.126\n",
       "367    0.220\n",
       "368    0.108\n",
       "369    0.188\n",
       "370    0.194\n",
       "371    0.202\n",
       "372    0.186\n",
       "373    0.186\n",
       "374    0.278\n",
       "375    0.230\n",
       "376    0.346\n",
       "377    0.390\n",
       "378    0.512\n",
       "379    0.630\n",
       "380    0.638\n",
       "385    0.100\n",
       "387    0.100\n",
       "388    0.190\n",
       "389    0.256\n",
       "390    0.296\n",
       "391    0.336\n",
       "393    0.632\n",
       "395    0.100\n",
       "396    0.100\n",
       "397    0.100\n",
       "398    0.306\n",
       "399    0.384\n",
       "400    0.154\n",
       "402    0.148\n",
       "403    0.752\n",
       "Name: accuracy, Length: 273, dtype: float64"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  \n",
    "\n",
    "\n",
    "user_info = ['user_id','user_experience','user_education_background']\n",
    "\n",
    "\n",
    "user_results = ['user_id','params','accuracy','time_taken']\n",
    "\n",
    "\n",
    "user_final_result = ['user_id','params','accuracy','time_taken']\n",
    "\n",
    "\n",
    "\n",
    "#exclude the geo codes column.\n",
    "dataset_user_info = pd.read_csv('./user_data/server_a/server_a_user_info.csv',skiprows=[0],usecols=[0,1,2],header=None,names=user_info)\n",
    "dataset_user_results = pd.read_csv('./user_data/server_a/server_a_user_results.csv',skiprows=[0],usecols=[1,2,3,4],header=None,names=user_results)\n",
    "dataset_user_final_results = pd.read_csv('./user_data/server_a/final_Results.csv',skiprows=[0],usecols=[1,2,3,4],header=None,names=user_final_result)\n",
    "\n",
    "#remove all -3 and -1 accuracies\n",
    "dataset_user_results_fanova = dataset_user_results\n",
    "dataset_user_results_fanova = dataset_user_results_fanova[dataset_user_results_fanova['accuracy']>0]\n",
    "dataset_user_results_fanova.accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_education_background</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_experience</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 user_id  user_education_background\n",
       "user_experience                                    \n",
       "0                      9                          9\n",
       "3                      7                          7\n",
       "4                      1                          1\n",
       "5                      1                          1\n",
       "6                      1                          1\n",
       "9                      3                          3\n",
       "10                     1                          1\n",
       "12                     5                          5\n",
       "18                     1                          1\n",
       "20                     4                          4\n",
       "24                     3                          3\n",
       "36                     1                          1"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_user_final_results.groupby('user_experience').count()\n",
    "# dataset_user_info.user_experience.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_user_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_user_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#it is same as dataset_user_results but with accuracy>=0\n",
    "dataset_user_results_fanova.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>params</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BC7935A</td>\n",
       "      <td>{\"epochs\": {\"value\": 100.0, \"comment\": 4, \"com...</td>\n",
       "      <td>0.772</td>\n",
       "      <td>1043.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6B392DA</td>\n",
       "      <td>{\"epochs\": {\"value\": 150.0, \"comment\": 1, \"com...</td>\n",
       "      <td>0.754</td>\n",
       "      <td>1527.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02AECEA</td>\n",
       "      <td>{\"epochs\": {\"value\": 25.0, \"comment\": 4, \"comm...</td>\n",
       "      <td>0.716</td>\n",
       "      <td>131.277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9950E8A</td>\n",
       "      <td>{\"epochs\": {\"value\": 90.0, \"comment\": 4, \"comm...</td>\n",
       "      <td>0.680</td>\n",
       "      <td>435.141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B65339A</td>\n",
       "      <td>{\"epochs\": {\"value\": 100.0, \"comment\": 4, \"com...</td>\n",
       "      <td>0.592</td>\n",
       "      <td>520.916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                             params  accuracy  \\\n",
       "0  BC7935A  {\"epochs\": {\"value\": 100.0, \"comment\": 4, \"com...     0.772   \n",
       "1  6B392DA  {\"epochs\": {\"value\": 150.0, \"comment\": 1, \"com...     0.754   \n",
       "2  02AECEA  {\"epochs\": {\"value\": 25.0, \"comment\": 4, \"comm...     0.716   \n",
       "3  9950E8A  {\"epochs\": {\"value\": 90.0, \"comment\": 4, \"comm...     0.680   \n",
       "4  B65339A  {\"epochs\": {\"value\": 100.0, \"comment\": 4, \"com...     0.592   \n",
       "\n",
       "   time_taken  \n",
       "0    1043.760  \n",
       "1    1527.990  \n",
       "2     131.277  \n",
       "3     435.141  \n",
       "4     520.916  "
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_user_final_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_rows(row):\n",
    "    global dataset_user_info\n",
    "    exp = None\n",
    "    education = None\n",
    "    for index, element in dataset_user_info.iterrows():\n",
    "        if element['user_id'] == row['user_id']:\n",
    "            exp = element['user_experience']\n",
    "            education = element['user_education_background']\n",
    "            break\n",
    "    if exp is not None and education is not None:\n",
    "        row['user_experience'] = exp\n",
    "        row['user_education_background'] = education\n",
    "    return row\n",
    "dataset_user_final_results.drop(['params'],inplace=True,axis=1)\n",
    "dataset_user_final_results = dataset_user_final_results.apply(lambda row: transform_rows(row),axis=1)\n",
    "dataset_user_final_results = dataset_user_final_results[dataset_user_final_results['accuracy']>=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time_taken</th>\n",
       "      <th>user_education_background</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_experience</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 user_id  accuracy  time_taken  user_education_background\n",
       "user_experience                                                          \n",
       "0                      8         8           8                          8\n",
       "3                      7         7           7                          7\n",
       "4                      1         1           1                          1\n",
       "5                      1         1           1                          1\n",
       "6                      1         1           1                          1\n",
       "9                      2         2           2                          2\n",
       "10                     1         1           1                          1\n",
       "12                     4         4           4                          4\n",
       "18                     1         1           1                          1\n",
       "20                     3         3           3                          3\n",
       "24                     1         1           1                          1\n",
       "36                     1         1           1                          1"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset_user_final_results.groupby('user_experience').count()\n",
    "# print(np.setdiff1d(dataset_user_final_results.user_id.tolist(),dataset_user_info.user_id.tolist()))\n",
    "# print(dataset_user_info.user_id.size)\n",
    "# print(dataset_user_final_results.user_id.size)\n",
    "\n",
    "# from collections import Counter\n",
    "# [k for (k,v) in Counter(dataset_user_final_results.user_id.tolist()).items() if v > 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#accuracy scatter plot\n",
    "zipped_values = [list(x) for x in zip(*sorted(zip(dataset_user_final_results['user_experience'],dataset_user_final_results['accuracy'],dataset_user_final_results['user_id']), key=itemgetter(0,1)))]\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(zipped_values[0],zipped_values[1])\n",
    "# ax.plot(keys,values)\n",
    "ax.set(xlabel='Experience (s)', ylabel='accuracy ',\n",
    "       title='Experience vs Accuracy (All data points)')\n",
    "ax.grid()\n",
    "plt.xticks(zipped_values[0])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy scatter plot average\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "a = [list(x) for x in zip(*sorted(zip(dataset_user_final_results['user_experience'],dataset_user_final_results['accuracy'],dataset_user_final_results['user_id']), key=itemgetter(0,1)))]\n",
    "n=len(a[0])\n",
    "dataset = {}\n",
    "for element in range(0,n):\n",
    "    if a[0][element] not in dataset:\n",
    "        dataset[a[0][element]] = {}\n",
    "        dataset[a[0][element]]['sum'] = a[1][element]\n",
    "        dataset[a[0][element]]['count'] = 1\n",
    "        \n",
    "    else:\n",
    "        dataset[a[0][element]]['sum']+= a[1][element]\n",
    "        dataset[a[0][element]]['count'] += 1\n",
    "print(dataset)\n",
    "print(a)\n",
    "keys = []\n",
    "values = []\n",
    "for key,value in dataset.items():\n",
    "    keys.append(key)\n",
    "    values.append(value['sum']/value['count'])\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(keys,values)\n",
    "ax.plot(keys,values)\n",
    "ax.set(xlabel='Experience (s)', ylabel='accuracy ',\n",
    "       title='About as simple as it gets, folks')\n",
    "ax.grid()\n",
    "plt.xticks(keys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#correlation value\n",
    "filtered = dataset_user_final_results[dataset_user_final_results['accuracy']>=0]\n",
    "# correlation = dataset_user_final_results['accuracy'].corr(dataset_user_final_results['user_experience'])\n",
    "variance_accuracy = np.var(filtered['accuracy'].tolist())\n",
    "std_accuracy = np.std(filtered['accuracy'].tolist())\n",
    "mean_accuracy = np.mean(filtered['accuracy'].tolist())\n",
    "print(\"Variance in accuracy {}\\n Deviation in accuracy {}\\n Mean of accuracy {}\\n\".format(variance_accuracy,std_accuracy,mean_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert json to columns and add exp, background and accuracy in single dataframe for both fanova and results row\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "data_dict = defaultdict(list)\n",
    "def transform_rows(row):\n",
    "    global dataset_user_info, data_dict\n",
    "    exp = None\n",
    "    education = None\n",
    "    for index, element in dataset_user_info.iterrows():\n",
    "        if element['user_id'] == row['user_id']:\n",
    "            exp = element['user_experience']\n",
    "            education = element['user_education_background']\n",
    "            break\n",
    "   \n",
    "    if exp is not None and education is not None:\n",
    "        row['user_experience'] = exp\n",
    "        row['user_education_background'] = education\n",
    "        \n",
    "    if row['lossFunction.value'] == \"cross_entropy\":\n",
    "        row['lossFunction.value'] = 1\n",
    "    \n",
    "    if row['lossFunction.value'] == \"negative_log_likelihood\":\n",
    "        row['lossFunction.value'] = 2\n",
    "    \n",
    "    if row['lossFunction.value'] == \"mean_squared_loss\":\n",
    "        row['lossFunction.value'] = 3\n",
    "    \n",
    "    if row['lossFunction.value'] == \"l1_loss\":\n",
    "        row['lossFunction.value'] = 4\n",
    "#     data_row = [row['accuracy'],row['epochs.value'],row['batchSize.value']]\n",
    "    data_row = [row['accuracy'],row['epochs.value'],row['batchSize.value']]\n",
    "    if row['optimizer.value'] == \"adam_optimizer\":\n",
    "        row['alpha.value'] = float('nan')\n",
    "        row['initialAccumulator.value'] = float('nan')\n",
    "        row['lambda.value'] = float('nan')\n",
    "        row['learningRateDecay.value'] = float('nan')\n",
    "        row['momentum.value'] = float('nan')\n",
    "        row['rho.value'] = float('nan')\n",
    "        data_row.extend([row['lossFunction.value'],row['beta1.value'],row['beta2.value'],row['weightDecay.value'],row['learningRate.value'],row['epsilon.value']])\n",
    "        data_dict[row['optimizer.value']].append(data_row)\n",
    "        row['optimizer.value'] = 1\n",
    "        \n",
    "    if row['optimizer.value'] == \"ada_delta\":\n",
    "        row['beta1.value'] = float('nan')\n",
    "        row['beta2.value'] = float('nan')\n",
    "        row['alpha.value'] = float('nan')\n",
    "        row['initialAccumulator.value'] = float('nan')\n",
    "        row['lambda.value'] = float('nan')\n",
    "        row['learningRateDecay.value'] = float('nan')\n",
    "        row['momentum.value'] = float('nan')\n",
    "        data_row.extend([row['lossFunction.value'],row['rho.value'],row['epsilon.value'],row['weightDecay.value'],row['learningRate.value']])\n",
    "        data_dict[row['optimizer.value']].append(data_row)\n",
    "        row['optimizer.value'] = 2\n",
    "        \n",
    "    if row['optimizer.value'] == \"averaged_sgd\":\n",
    "        row['beta1.value'] = float('nan')\n",
    "        row['beta2.value'] = float('nan')\n",
    "        row['epsilon.value'] = float('nan')\n",
    "        row['initialAccumulator.value'] = float('nan')\n",
    "        row['learningRateDecay.value'] = float('nan')\n",
    "        row['momentum.value'] = float('nan')\n",
    "        row['rho.value'] = float('nan')\n",
    "        data_row.extend([row['lossFunction.value'],row['alpha.value'],row['lambda.value'],row['weightDecay.value'],row['learningRate.value']])\n",
    "        data_dict[row['optimizer.value']].append(data_row)\n",
    "        row['optimizer.value'] = 3\n",
    "       \n",
    "    if row['optimizer.value'] == \"rms_prop\":\n",
    "        row['beta1.value'] = float('nan')\n",
    "        row['beta2.value'] = float('nan')\n",
    "        row['initialAccumulator.value'] = float('nan')\n",
    "        row['lambda.value'] = float('nan')\n",
    "        row['learningRateDecay.value'] = float('nan')\n",
    "        row['rho.value'] = float('nan')\n",
    "        data_row.extend([row['lossFunction.value'],row['momentum.value'],row['alpha.value'],row['weightDecay.value'],row['learningRate.value'],row['epsilon.value']])\n",
    "        data_dict[row['optimizer.value']].append(data_row)\n",
    "        row['optimizer.value'] = 4\n",
    "        \n",
    "    if row['optimizer.value'] == \"sgd\":\n",
    "        row['beta1.value'] = float('nan')\n",
    "        row['beta2.value'] = float('nan')\n",
    "        row['epsilon.value'] = float('nan')\n",
    "        row['alpha.value'] = float('nan')\n",
    "        row['initialAccumulator.value'] = float('nan')\n",
    "        row['lambda.value'] = float('nan')\n",
    "        row['learningRateDecay.value'] = float('nan')\n",
    "        row['rho.value'] = float('nan')\n",
    "        data_row.extend([row['lossFunction.value'],row['momentum.value'],row['weightDecay.value'],row['learningRate.value']])\n",
    "        data_dict[row['optimizer.value']].append(data_row)\n",
    "        row['optimizer.value'] = 5\n",
    "        \n",
    "    if row['optimizer.value'] == \"ada_grad\":\n",
    "        row['beta1.value'] = float('nan')\n",
    "        row['beta2.value'] = float('nan')\n",
    "        row['epsilon.value'] = float('nan')\n",
    "        row['alpha.value'] = float('nan')\n",
    "        row['lambda.value'] = float('nan')\n",
    "        row['momentum.value'] = float('nan')\n",
    "        row['rho.value'] = float('nan')\n",
    "        data_row.extend([row['lossFunction.value'],row['initialAccumulator.value'],row['learningRateDecay.value'],row['weightDecay.value'],row['learningRate.value']])\n",
    "        data_dict[row['optimizer.value']].append(data_row)\n",
    "        row['optimizer.value'] = 6\n",
    "    \n",
    "    return row\n",
    "\n",
    "json_to_columns_results = pd.io.json.json_normalize(dataset_user_results.params.apply(json.loads))\n",
    "\n",
    "#set index\n",
    "dataset_user_results = dataset_user_results.set_index(np.arange(0,404,1))\n",
    "\n",
    "json_to_columns_results['accuracy'] = dataset_user_results['accuracy']\n",
    "json_to_columns_results['time_taken'] = dataset_user_results['time_taken']\n",
    "\n",
    "\n",
    "json_to_columns_results = json_to_columns_results.apply(lambda row: transform_rows(row),axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "json_to_columns_fanova = pd.io.json.json_normalize(dataset_user_results_fanova.params.apply(json.loads))\n",
    "\n",
    "#set index\n",
    "dataset_user_results_fanova = dataset_user_results_fanova.set_index(np.arange(0,273,1))\n",
    "\n",
    "json_to_columns_fanova['accuracy'] = dataset_user_results_fanova['accuracy']\n",
    "\n",
    "json_to_columns_fanova = json_to_columns_fanova.apply(lambda row: transform_rows(row),axis=1)\n",
    "\n",
    "\n",
    "json_to_columns_fanova['time_taken'] = dataset_user_results_fanova['time_taken']\n",
    "print(data_dict)\n",
    "# print(json_to_columns_fanova.accuracy)\n",
    "\n",
    "# print(\"user df size: {} and fanova result size: {}\".format(json_to_columns_results.user_id.size,json_to_columns_fanova.user_id.size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#strategy experiments\n",
    "#divide it into age groups <=3, (3-9],>9 \n",
    "\n",
    "print(json_to_columns_fanova.columns)\n",
    "\n",
    "group1 = json_to_columns_results['user_experience']<=3\n",
    "group2 = (json_to_columns_results['user_experience']>3) & (json_to_columns_results['user_experience']<=9)\n",
    "group3 = (json_to_columns_results['user_experience']>9) & (json_to_columns_results['user_experience']<=36)\n",
    "\n",
    "json_to_columns_results_3 = json_to_columns_results[group1]\n",
    "json_to_columns_results_9 = json_to_columns_results[group2]\n",
    "json_to_columns_results_36 = json_to_columns_results[group3]\n",
    "\n",
    "\n",
    "group3_tries  = json_to_columns_results_3.user_id.size//pd.unique(json_to_columns_results_3.user_id).size\n",
    "group9_tries  = json_to_columns_results_9.user_id.size//pd.unique(json_to_columns_results_9.user_id).size\n",
    "group36_tries = json_to_columns_results_36.user_id.size//pd.unique(json_to_columns_results_36.user_id).size\n",
    "\n",
    "group3_total_time = sum(json_to_columns_results_3.time_taken)//(pd.unique(json_to_columns_results_3.user_id).size*60)\n",
    "group9_total_time = sum(json_to_columns_results_9.time_taken)//(pd.unique(json_to_columns_results_9.user_id).size*60)\n",
    "group36_total_time = sum(json_to_columns_results_36.time_taken)//(pd.unique(json_to_columns_results_36.user_id).size*60)\n",
    "\n",
    "group3_each_run_time = group3_total_time/group3_tries\n",
    "group9_each_run_time = group9_total_time/group9_tries\n",
    "group36_each_run_time = group36_total_time/group36_tries\n",
    "\n",
    "\n",
    "print(\"rows in group1:{} group2:{} and group3:{}\".format(json_to_columns_results_3.user_id.size,json_to_columns_results_9.user_id.size,json_to_columns_results_36.user_id.size))\n",
    "# print(\"Avg parameters tried based on experience group1:{} group2:{} and group3:{}\".format(json_to_columns_results_3.user_id.size//pd.unique(json_to_columns_results_3.user_id).size,json_to_columns_results_9.user_id.size//pd.unique(json_to_columns_results_9.user_id).size,json_to_columns_results_36.user_id.size//pd.unique(json_to_columns_results_36.user_id).size))\n",
    "# print(\"Avg time for each user took based on experience group1:{} group2:{} and group3:{}\".format(sum(json_to_columns_results_3.time_taken)//(pd.unique(json_to_columns_results_3.user_id).size*60),sum(json_to_columns_results_9.time_taken)//(pd.unique(json_to_columns_results_9.user_id).size*60),sum(json_to_columns_results_36.time_taken)//(60*pd.unique(json_to_columns_results_36.user_id).size)))\n",
    "# print(\"Avg time each user took on one job group1:{} group2:{} and group3:{}\".format(sum(json_to_columns_results_3.time_taken)//(pd.unique(json_to_columns_results_3.user_id).size*60),sum(json_to_columns_results_9.time_taken)//(pd.unique(json_to_columns_results_9.user_id).size*60),sum(json_to_columns_results_36.time_taken)//(60*pd.unique(json_to_columns_results_36.user_id).size)))\n",
    "\n",
    "print(\"Avg parameters tried based on experience group1:{} group2:{} and group3:{}\".format(group3_tries,group9_tries,group36_tries))\n",
    "print(\"Avg time for took based on experience group1:{} group2:{} and group3:{}\".format(group3_total_time,group9_total_time,group36_total_time))\n",
    "print(\"Avg time each user took on one job group1:{} group2:{} and group3:{}\".format(group3_each_run_time,group9_each_run_time,group36_each_run_time))\n",
    "\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group1_fanova = json_to_columns_fanova['user_experience']<=3\n",
    "group2_fanova = (json_to_columns_fanova['user_experience']>3) & (json_to_columns_fanova['user_experience']<=9)\n",
    "group3_fanova = (json_to_columns_fanova['user_experience']>9) & (json_to_columns_fanova['user_experience']<=36)\n",
    "\n",
    "json_to_columns_fanova_3 = json_to_columns_fanova[group1_fanova]\n",
    "json_to_columns_fanova_9 = json_to_columns_fanova[group2_fanova]\n",
    "json_to_columns_fanova_36 = json_to_columns_fanova[group3_fanova]\n",
    "\n",
    "\n",
    "from scipy.stats import kruskal,f_oneway\n",
    "stat, p = kruskal(json_to_columns_fanova_3['accuracy'], json_to_columns_fanova_9['accuracy'], json_to_columns_fanova_36['accuracy'])\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distributions (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distributions (reject H0)')\n",
    "\n",
    "\n",
    "stat, p = f_oneway(json_to_columns_fanova_3['accuracy'], json_to_columns_fanova_9['accuracy'], json_to_columns_fanova_36['accuracy'])\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "# interpret\n",
    "if p > alpha:\n",
    "    print('Same distributions f_oneway (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distributions f_oneway (reject H0)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "for key, val in data_dict.items():\n",
    "    w = csv.writer(open(\"/Users/kanavanand/Desktop/user_data/thesis-implementation/le-net/user_data/analysis/\"+key+\".csv\", \"w\"))\n",
    "    x = csv.writer(open(\"/Users/kanavanand/Desktop/user_data/thesis-implementation/le-net/user_data/analysis/\"+key+\"-accuracy.csv\", \"w\"))\n",
    "\n",
    "    for element in val:\n",
    "        w.writerow(element[1:])\n",
    "        x.writerow([element[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(json_to_columns_fanova['accuracy'])\n",
    "accuracy = json_to_columns_fanova['accuracy'].tolist()\n",
    "dropped_fanova = json_to_columns_fanova.drop(['alpha.value','beta1.value','beta2.value','epsilon.value','initialAccumulator.value','lambda.value','learningRate.value','learningRateDecay.value','momentum.value','rho.value','weightDecay.value','time_taken','finalSubmission.value','user_experience','user_education_background','user_id','accuracy','alpha.comment','alpha.comment_other','batchSize.comment','batchSize.comment_other','beta1.comment','beta1.comment_other','beta2.comment','beta2.comment_other','epochs.comment','epochs.comment_other','epsilon.comment','epsilon.comment_other','initialAccumulator.comment','initialAccumulator.comment_other','lambda.comment','lambda.comment_other','learningRate.comment','learningRate.comment_other','learningRateDecay.comment','learningRateDecay.comment_other','lossFunction.comment','lossFunction.comment_other','momentum.comment','momentum.comment_other','optimizer.comment','optimizer.comment_other','rho.comment','rho.comment_other','weightDecay.comment','weightDecay.comment_other'],axis=1)\n",
    "print(dropped_fanova.head())\n",
    "dropped_fanova.to_csv(path_or_buf=\"/Users/kanavanand/Desktop/user_data/thesis-implementation/le-net/user_data/analysis/features.csv\",index=False)\n",
    "\n",
    "with open('/Users/kanavanand/Desktop/user_data/thesis-implementation/le-net/user_data/analysis/accuracy.csv', 'w') as f:\n",
    "    for item in accuracy:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fanova import fANOVA\n",
    "import fanova.visualizer\n",
    "import ConfigSpace\n",
    "from ConfigSpace.hyperparameters import UniformFloatHyperparameter\n",
    "import os\n",
    "path = os.path.dirname(os.path.realpath(__file__))\n",
    "# directory in which you can find all plots\n",
    "plot_dir = path + '/plots/'\n",
    "# artificial dataset (here: features)\n",
    "#features = np.loadtxt(path + '/fanova/features.csv', delimiter=\",\")\n",
    "#responses = np.loadtxt(path + '/fanova/accuracy.csv', delimiter=\",\")\n",
    "#features = features[1:]\n",
    "files = ['adam_optimizer','ada_grad','ada_delta','averaged_sgd','sgd','rms_prop']\n",
    "for element in files:\n",
    "    features = np.loadtxt(path + '/thesis-implementation/le-net/user_data/analysis/'+element+'.csv', delimiter=\",\")\n",
    "    responses = np.loadtxt(path + '/thesis-implementation/le-net/user_data/analysis/'+element+'-accuracy.csv', delimiter=\",\")\n",
    "    # config space\n",
    "    pcs = list(zip(np.min(features,axis=0), np.max(features, axis=0)))\n",
    "    cs = ConfigSpace.ConfigurationSpace()\n",
    "    for i in range(len(pcs)):\n",
    "        cs.add_hyperparameter(UniformFloatHyperparameter(\"%i\" %i, pcs[i][0], pcs[i][1]))\n",
    "            # create an instance of fanova with trained forest and ConfigSpace\n",
    "    f = fANOVA(X = features, Y = responses, config_space=cs)\n",
    "            # marginal of particular parameter:\n",
    "    dims = (1, )\n",
    "    print(\"Displaying importantance of each HP for {}:\".format(element))\n",
    "    for index in range(0,len(features[0])):\n",
    "        res = f.quantify_importance((index, ))\n",
    "        print(res)\n",
    "            # getting the 10 most important pairwise marginals sorted by importance\n",
    "    best_margs = f.get_triple_marginals(n=3)\n",
    "    print(best_margs)\n",
    "            # visualizations:\n",
    "            # first create an instance of the visualizer with fanova object and configspace\n",
    "vis = fanova.visualizer.Visualizer(f, cs,directory=plot_dir)\n",
    "        # creating the plot of pairwise marginal:\n",
    "vis.plot_pairwise_marginal((0,2), resolution=20)\n",
    "        # creating all plots in the directory\n",
    "vis.create_all_plots(plot_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
